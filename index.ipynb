{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Trees using scikit-learn - Lab\n",
    "\n",
    "## Introduction\n",
    "Following the toy example we saw in the previous lesson, we shall now grow a decision tree for a more complex dataset. This lab covers all major areas of standard machine learning practice , from data acquisition to evaluation of results. We shall use scikit learn, pandas and graphviz libraries to conduct this analysis following the example of play tennis dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Use pandas to prepare the data for the scikit-learn decision tree algorithm\n",
    "- Train the classifier with a training dataset and evaluate performance using different measures\n",
    "- Visualize the decision tree and interpret the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCI Banknote Authentication Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we shall work with a popular dataset for classification called the [\"UCI Bank Note Authentication Dataset'](https://archive.ics.uci.edu/ml/datasets/banknote+authentication). This Data were extracted from images that were taken from genuine and forged banknote-like specimens. The notes were first digitized, followed by a numerical transformation using DSP techniques. The final set of engineered features are all continuous in nature (visit the UCI link to learn about feature engineering in detail). \n",
    "\n",
    "We have following attributes in the dataset. \n",
    "\n",
    "1. __Variance__ of Wavelet Transformed image (continuous) \n",
    "2. __Skewness__ of Wavelet Transformed image (continuous) \n",
    "3. __Curtosis__ of Wavelet Transformed image (continuous) \n",
    "4. __Entropy__ of image (continuous) \n",
    "5. __Class__ (integer) - Target/Label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary Libraries\n",
    "- Import necessary libraries as we saw in previous lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import tree \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Data\n",
    "- Read the file `\"data_banknote_authentication.csv\"` as a pandas dataframe. Note that there is no header information in this dataset.\n",
    "- Assign column names 'Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class' to dataset in the given order.\n",
    "- View the basic statistics and shape of dataset.\n",
    "- Check for frequency of positive and negative examples in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "df = pd.read_csv(\"data_banknote_authentication.csv\",names=['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variance     Skewness     Curtosis      Entropy        Class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    762\n",
       "1    610\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class frequency of target variable \n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Observations \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Features and Labels, Training and Test Data\n",
    "\n",
    "So now we need to create our feature set X and labels y. \n",
    "- Create X and y by selecting the appropriate columns from the dataset\n",
    "- Create a 80/20 split on the dataset for training/testing. Use random_state=10 for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Classifier and Make PRedictions\n",
    "- Create an instance of decision tree classifier with random_state=10 for reproducibility\n",
    "- Fit the traiing data to the model \n",
    "- USe the trained model to make predictions with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a DT classifier\n",
    "classifier = DecisionTreeClassifier(random_state=10)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test data\n",
    "\n",
    "## Your code here \n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check Predictive Performance\n",
    "\n",
    "We can now use different evaluation measures to check the predictive performance of the classifier. \n",
    "- Check the accuracy , AUC and create a confusion matrix \n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :97.81818181818181\n",
      "\n",
      "AUC is :0.98\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>152</td>\n",
       "      <td>123</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "True                    \n",
       "0          149    3  152\n",
       "1            3  120  123\n",
       "All        152  123  275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Accuracy , AUC and Confusion matrix \n",
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUC is :{0}\".format(round(roc_auc,2)))\n",
    "\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your observations here \n",
    "\n",
    "All but __6__ of the observations were identified correctly. This prediction was very accurate, _97.81%_ in our first go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize the tree \n",
    "\n",
    "- Use graphviz to visualize the tree \n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.6.7\n",
      "  latest version: 4.6.8\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/learn-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - graphviz\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.3.9   |       hecc5488_0         146 KB  conda-forge\n",
      "    cairo-1.14.12              |       h8948797_3         1.3 MB  defaults\n",
      "    certifi-2019.3.9           |           py36_0         149 KB  conda-forge\n",
      "    gettext-0.19.8.1           |    h9745a5d_1001         3.7 MB  conda-forge\n",
      "    graphite2-1.3.13           |    hf484d3e_1000         109 KB  conda-forge\n",
      "    graphviz-2.38.0            |    hcf1ce16_1009         9.7 MB  conda-forge\n",
      "    harfbuzz-1.9.0             |    he243708_1001         957 KB  conda-forge\n",
      "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
      "    libtiff-4.0.10             |    h648cc4a_1001         592 KB  conda-forge\n",
      "    libtool-2.4.6              |    h14c3975_1002         512 KB  conda-forge\n",
      "    openssl-1.0.2r             |       h14c3975_0         3.1 MB  conda-forge\n",
      "    pango-1.40.14              |       he752989_2         527 KB  conda-forge\n",
      "    pixman-0.34.0              |    h14c3975_1003         595 KB  conda-forge\n",
      "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
      "    xorg-libice-1.0.9          |    h516909a_1004          58 KB  conda-forge\n",
      "    xorg-libsm-1.2.2           |       h470a237_5          24 KB  conda-forge\n",
      "    xorg-libx11-1.6.7          |    h14c3975_1000         940 KB  conda-forge\n",
      "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
      "    xorg-libxpm-3.5.12         |    h14c3975_1002          64 KB  conda-forge\n",
      "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
      "    xorg-libxt-1.1.5           |    h14c3975_1002         367 KB  conda-forge\n",
      "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
      "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
      "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        23.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
      "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h9745a5d_1001\n",
      "  graphite2          conda-forge/linux-64::graphite2-1.3.13-hf484d3e_1000\n",
      "  graphviz           conda-forge/linux-64::graphviz-2.38.0-hcf1ce16_1009\n",
      "  harfbuzz           conda-forge/linux-64::harfbuzz-1.9.0-he243708_1001\n",
      "  libtiff            conda-forge/linux-64::libtiff-4.0.10-h648cc4a_1001\n",
      "  libtool            conda-forge/linux-64::libtool-2.4.6-h14c3975_1002\n",
      "  pango              conda-forge/linux-64::pango-1.40.14-he752989_2\n",
      "  pixman             conda-forge/linux-64::pixman-0.34.0-h14c3975_1003\n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.9-h516909a_1004\n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.2-h470a237_5\n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.7-h14c3975_1000\n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
      "  xorg-libxpm        conda-forge/linux-64::xorg-libxpm-3.5.12-h14c3975_1002\n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
      "  xorg-libxt         conda-forge/linux-64::xorg-libxt-1.1.5-h14c3975_1002\n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2018.03.07~ --> conda-forge::ca-certificates-2019.3.9-hecc5488_0\n",
      "  certifi               pkgs/main::certifi-2018.8.13-py36_0 --> conda-forge::certifi-2019.3.9-py36_0\n",
      "  jpeg                        pkgs/main::jpeg-9b-h024ee3a_2 --> conda-forge::jpeg-9c-h14c3975_1001\n",
      "  openssl              pkgs/main::openssl-1.0.2p-h14c3975_0 --> conda-forge::openssl-1.0.2r-h14c3975_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "\n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2f254a27a30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, prog)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             self.__setattr__(\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m                 \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m             )\n\u001b[1;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# Visualize the tree trained from complete dataset\n",
    "\n",
    "## Your code here \n",
    "# Visualize the tree trained from complete dataset\n",
    "dot_data = StringIO()\n",
    "export_graphviz(classifier, out_file=dot_data, filled=True, rounded=True,special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your observations here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Re-grow the Tree Using Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO in the above example, we used all default settings for decision tree classifier. The default impurity crietrion in scikit learn is the Gini impurity. We can change it back to entropy by passing in `criterion='entropy'` argument to the classifier in the training phase. \n",
    "- Repeat the above tasks for training, evaluation and visualization using Entropy measure. (\n",
    "- Compare and interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :99.63636363636364\n",
      "\n",
      "AUC is :1.0\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>151</td>\n",
       "      <td>124</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "True                    \n",
       "0          151    1  152\n",
       "1            0  123  123\n",
       "All        151  124  275"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2 = DecisionTreeClassifier(random_state=10,criterion='entropy')  \n",
    "classifier_2.fit(X_train, y_train)  \n",
    "\n",
    "y_pred_2 = classifier_2.predict(X_test)\n",
    "## Your code here \n",
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test,y_pred_2) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "\n",
    "# Check the AUC for predictions\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_2)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print(\"\\nAUC is :{0}\".format(round(roc_auc,2)))\n",
    "\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "pd.crosstab(y_test, y_pred_2, rownames=['True'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observations here \n",
    "\n",
    "# With entropy we see a much lower accuracy and AUC than earlier\n",
    "# Only one false positive value , leading to accuracy of 99%\n",
    "# The tree shape changes considerably with change in impurity criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional \n",
    "\n",
    "- We discussed earlier that decision trees are very sensitive towards outliers. Try to identify and remove/fix any possible outliers in the dataset. \n",
    "- Check the distributions of the data. Is there any room for normalization/scaling of data ? Apply these techiques and see if it improves upon accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we looked at growing a decision tree for banknote authentication dataset which is composed of extracted continuous features from photographic data. We looked at different stages of the experiment including data acquisition, training, prediction and evaluation. We also looked at growing trees using entropy vs. gini impurity criteria. In following lessons, we shall look at some more such pre-train tuning techniques for ensuring an optimal classifier for learning and prediction.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
